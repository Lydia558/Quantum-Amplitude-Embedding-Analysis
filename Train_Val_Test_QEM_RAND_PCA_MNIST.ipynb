{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e970c6e-ee65-4f06-bb77-53863c2f5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNN] Epoch 1 finished\n",
      "[CNN-VAL] Accuracy: 98.28%\n",
      "[CNN] Epoch 2 finished\n",
      "[CNN-VAL] Accuracy: 98.17%\n",
      "[Extract] train: torch.Size([54000, 128])\n",
      "[Extract] val: torch.Size([6000, 128])\n",
      "[Extract] test: torch.Size([10000, 128])\n",
      "\n",
      "==================================================\n",
      "PCA\n",
      "==================================================\n",
      "PCA reduced to 7 dims, variance explained 0.797\n",
      "[PCA-MLP] Epoch: 1 [0/54000] Loss: 5.926607\n",
      "[PCA-MLP] Epoch: 1 [6400/54000] Loss: 0.386174\n",
      "[PCA-MLP] Epoch: 1 [12800/54000] Loss: 0.264391\n",
      "[PCA-MLP] Epoch: 1 [19200/54000] Loss: 0.077076\n",
      "[PCA-MLP] Epoch: 1 [25600/54000] Loss: 0.022681\n",
      "[PCA-MLP] Epoch: 1 [32000/54000] Loss: 0.011295\n",
      "[PCA-MLP] Epoch: 1 [38400/54000] Loss: 0.175794\n",
      "[PCA-MLP] Epoch: 1 [44800/54000] Loss: 0.110930\n",
      "[PCA-MLP] Epoch: 1 [51200/54000] Loss: 0.141165\n",
      "[PCA-MLP] Epoch 1 finished\n",
      "[PCA-MLP-VAL] Accuracy: 97.17%\n",
      "[PCA-MLP-TEST] Accuracy: 97.62%\n",
      "[PCA-MLP] Epoch: 2 [0/54000] Loss: 0.117383\n",
      "[PCA-MLP] Epoch: 2 [6400/54000] Loss: 0.032892\n",
      "[PCA-MLP] Epoch: 2 [12800/54000] Loss: 0.014607\n",
      "[PCA-MLP] Epoch: 2 [19200/54000] Loss: 0.079382\n",
      "[PCA-MLP] Epoch: 2 [25600/54000] Loss: 0.033876\n",
      "[PCA-MLP] Epoch: 2 [32000/54000] Loss: 0.079410\n",
      "[PCA-MLP] Epoch: 2 [38400/54000] Loss: 0.172880\n",
      "[PCA-MLP] Epoch: 2 [44800/54000] Loss: 0.009117\n",
      "[PCA-MLP] Epoch: 2 [51200/54000] Loss: 0.130784\n",
      "[PCA-MLP] Epoch 2 finished\n",
      "[PCA-MLP-VAL] Accuracy: 97.35%\n",
      "[PCA-MLP-TEST] Accuracy: 97.81%\n",
      "[PCA-MLP] Epoch: 3 [0/54000] Loss: 0.125587\n",
      "[PCA-MLP] Epoch: 3 [6400/54000] Loss: 0.118966\n",
      "[PCA-MLP] Epoch: 3 [12800/54000] Loss: 0.008626\n",
      "[PCA-MLP] Epoch: 3 [19200/54000] Loss: 0.018676\n",
      "[PCA-MLP] Epoch: 3 [25600/54000] Loss: 0.028465\n",
      "[PCA-MLP] Epoch: 3 [32000/54000] Loss: 0.166328\n",
      "[PCA-MLP] Epoch: 3 [38400/54000] Loss: 0.059978\n",
      "[PCA-MLP] Epoch: 3 [44800/54000] Loss: 0.048610\n",
      "[PCA-MLP] Epoch: 3 [51200/54000] Loss: 0.072404\n",
      "[PCA-MLP] Epoch 3 finished\n",
      "[PCA-MLP-VAL] Accuracy: 97.02%\n",
      "[PCA-MLP-TEST] Accuracy: 97.60%\n",
      "[PCA-MLP] Epoch: 4 [0/54000] Loss: 0.058408\n",
      "[PCA-MLP] Epoch: 4 [6400/54000] Loss: 0.044763\n",
      "[PCA-MLP] Epoch: 4 [12800/54000] Loss: 0.006978\n",
      "[PCA-MLP] Epoch: 4 [19200/54000] Loss: 0.040635\n",
      "[PCA-MLP] Epoch: 4 [25600/54000] Loss: 0.047195\n",
      "[PCA-MLP] Epoch: 4 [32000/54000] Loss: 0.018456\n",
      "[PCA-MLP] Epoch: 4 [38400/54000] Loss: 0.013529\n",
      "[PCA-MLP] Epoch: 4 [44800/54000] Loss: 0.030121\n",
      "[PCA-MLP] Epoch: 4 [51200/54000] Loss: 0.007082\n",
      "[PCA-MLP] Epoch 4 finished\n",
      "[PCA-MLP-VAL] Accuracy: 97.32%\n",
      "[PCA-MLP-TEST] Accuracy: 97.85%\n",
      "\n",
      "==================================================\n",
      "MLP\n",
      "==================================================\n",
      "Random Projection: 128 ‚Üí 7\n",
      "[RP-MLP] Epoch: 1 [0/54000] Loss: 3.349432\n",
      "[RP-MLP] Epoch: 1 [6400/54000] Loss: 0.650287\n",
      "[RP-MLP] Epoch: 1 [12800/54000] Loss: 0.443064\n",
      "[RP-MLP] Epoch: 1 [19200/54000] Loss: 0.286579\n",
      "[RP-MLP] Epoch: 1 [25600/54000] Loss: 0.394211\n",
      "[RP-MLP] Epoch: 1 [32000/54000] Loss: 0.297086\n",
      "[RP-MLP] Epoch: 1 [38400/54000] Loss: 0.322502\n",
      "[RP-MLP] Epoch: 1 [44800/54000] Loss: 0.292255\n",
      "[RP-MLP] Epoch: 1 [51200/54000] Loss: 0.417783\n",
      "[RP-MLP] Epoch 1 finished\n",
      "[RP-MLP-VAL] Accuracy: 87.50%\n",
      "[RP-MLP-TEST] Accuracy: 88.11%\n",
      "[RP-MLP] Epoch: 2 [0/54000] Loss: 0.251546\n",
      "[RP-MLP] Epoch: 2 [6400/54000] Loss: 0.244049\n",
      "[RP-MLP] Epoch: 2 [12800/54000] Loss: 0.335206\n",
      "[RP-MLP] Epoch: 2 [19200/54000] Loss: 0.357863\n",
      "[RP-MLP] Epoch: 2 [25600/54000] Loss: 0.237506\n",
      "[RP-MLP] Epoch: 2 [32000/54000] Loss: 0.310657\n",
      "[RP-MLP] Epoch: 2 [38400/54000] Loss: 0.294780\n",
      "[RP-MLP] Epoch: 2 [44800/54000] Loss: 0.299521\n",
      "[RP-MLP] Epoch: 2 [51200/54000] Loss: 0.292582\n",
      "[RP-MLP] Epoch 2 finished\n",
      "[RP-MLP-VAL] Accuracy: 87.82%\n",
      "[RP-MLP-TEST] Accuracy: 88.45%\n",
      "[RP-MLP] Epoch: 3 [0/54000] Loss: 0.282089\n",
      "[RP-MLP] Epoch: 3 [6400/54000] Loss: 0.261285\n",
      "[RP-MLP] Epoch: 3 [12800/54000] Loss: 0.259812\n",
      "[RP-MLP] Epoch: 3 [19200/54000] Loss: 0.455588\n",
      "[RP-MLP] Epoch: 3 [25600/54000] Loss: 0.266076\n",
      "[RP-MLP] Epoch: 3 [32000/54000] Loss: 0.326277\n",
      "[RP-MLP] Epoch: 3 [38400/54000] Loss: 0.461070\n",
      "[RP-MLP] Epoch: 3 [44800/54000] Loss: 0.335171\n",
      "[RP-MLP] Epoch: 3 [51200/54000] Loss: 0.254216\n",
      "[RP-MLP] Epoch 3 finished\n",
      "[RP-MLP-VAL] Accuracy: 89.22%\n",
      "[RP-MLP-TEST] Accuracy: 89.97%\n",
      "[RP-MLP] Epoch: 4 [0/54000] Loss: 0.269114\n",
      "[RP-MLP] Epoch: 4 [6400/54000] Loss: 0.334263\n",
      "[RP-MLP] Epoch: 4 [12800/54000] Loss: 0.309422\n",
      "[RP-MLP] Epoch: 4 [19200/54000] Loss: 0.190681\n",
      "[RP-MLP] Epoch: 4 [25600/54000] Loss: 0.136989\n",
      "[RP-MLP] Epoch: 4 [32000/54000] Loss: 0.400544\n",
      "[RP-MLP] Epoch: 4 [38400/54000] Loss: 0.397207\n",
      "[RP-MLP] Epoch: 4 [44800/54000] Loss: 0.264373\n",
      "[RP-MLP] Epoch: 4 [51200/54000] Loss: 0.246626\n",
      "[RP-MLP] Epoch 4 finished\n",
      "[RP-MLP-VAL] Accuracy: 89.53%\n",
      "[RP-MLP-TEST] Accuracy: 89.94%\n",
      "\n",
      "==================================================\n",
      "QEB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MNIST CNN + Dimensionality Reduction (PCA vs Random Projection vs QEB) + MLP\n",
    "Train / Validation / Test feature extraction \n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "# ========== Config ==========\n",
    "class Config:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_PATH = \"./data\"\n",
    "    BATCH_SIZE = 64\n",
    "    TEST_BATCH_SIZE = 1000\n",
    "    CNN_HIDDEN_DIM = 128\n",
    "    PROJECTION_DIM = 7\n",
    "    MLP_HIDDEN_DIM = 64\n",
    "    NUM_CLASSES = 10\n",
    "    LEARNING_RATE = 0.001\n",
    "    CNN_EPOCHS = 2\n",
    "    MLP_EPOCHS = 5\n",
    "    LOG_INTERVAL = 100\n",
    "    RANDOM_SEED = 42\n",
    "    VAL_RATIO = 0.1   # validation split ratio\n",
    "\n",
    "# Models\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x, return_features=False):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        features = self.fc1(x)\n",
    "        x = F.relu(features)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        if return_features:\n",
    "            return output, features\n",
    "        return output\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        _, features = self.forward(x, return_features=True)\n",
    "        return features\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# Data\n",
    "def get_mnist_loaders(config):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    full_train_dataset = datasets.MNIST(config.DATA_PATH, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(config.DATA_PATH, train=False, download=True, transform=transform)\n",
    "\n",
    "    # train/validation split\n",
    "    val_size = int(len(full_train_dataset) * config.VAL_RATIO)\n",
    "    train_size = len(full_train_dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Feature Extraction\n",
    "def extract_hidden_representations(model, dataloader, device, name=\"set\"):\n",
    "    model.eval()\n",
    "    all_features, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            features = model.extract_features(data)\n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(target.cpu())\n",
    "    features = torch.cat(all_features)\n",
    "    labels = torch.cat(all_labels)\n",
    "    print(f\"[Extract] {name}: {features.shape}\")\n",
    "    return features, labels\n",
    "\n",
    "def apply_pca(train_features, val_features, test_features, n_components=7):\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    train_pca = pca.fit_transform(train_features.numpy())\n",
    "    val_pca = pca.transform(val_features.numpy())\n",
    "    test_pca = pca.transform(test_features.numpy())\n",
    "    print(f\"PCA reduced to {n_components} dims, variance explained {pca.explained_variance_ratio_.sum():.3f}\")\n",
    "    return (torch.tensor(train_pca, dtype=torch.float32),\n",
    "            torch.tensor(val_pca, dtype=torch.float32),\n",
    "            torch.tensor(test_pca, dtype=torch.float32))\n",
    "\n",
    "def apply_random_projection(train_features, val_features, test_features, target_dim=7, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    input_dim = train_features.shape[1]\n",
    "    proj_matrix = torch.randn(input_dim, target_dim)\n",
    "    proj_matrix = proj_matrix / torch.norm(proj_matrix, dim=0, keepdim=True)\n",
    "\n",
    "    train_proj = train_features @ proj_matrix #torch.matmul(A,B) Îûë A@BÎûë ÎèôÏùº\n",
    "    val_proj = val_features @ proj_matrix\n",
    "    test_proj = test_features @ proj_matrix\n",
    "    print(f\"Random Projection: {input_dim} ‚Üí {target_dim}\")\n",
    "    return train_proj, val_proj, test_proj\n",
    "\n",
    "# Quantum Embedding\n",
    "n_qubits = 7\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "def quantum_embedding(x, weights):\n",
    "    # üîπ Amplitude Embedding\n",
    "    qml.AmplitudeEmbedding(x, wires=range(n_qubits), normalize=True)\n",
    "    \n",
    "    # üîπ PQC (RY + CNOT)\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(weights[i], wires=i)\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    # üîπ Í∞Å ÌÅêÎπÑÌä∏ Z expectation Î∞òÌôò\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class QuantumEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, n_qubits=7, n_features=128):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_features = n_features\n",
    "        self.embed_dim = 2**n_qubits\n",
    "        # ÌïôÏäµ Í∞ÄÎä•Ìïú ÌååÎùºÎØ∏ÌÑ∞ (RY Í∞ÅÎèÑ)\n",
    "        self.weights = nn.Parameter(torch.randn(n_qubits) * 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_out = []\n",
    "        for sample in x:\n",
    "            # Í∞Å sampleÏùÑ quantum embeddingÏúºÎ°ú Î≥ÄÌôò\n",
    "            q_result = quantum_embedding(sample.detach().cpu(), self.weights)\n",
    "            q_result = torch.as_tensor(q_result, device=x.device).float()\n",
    "            q_out.append(q_result)\n",
    "        return torch.stack(q_out)\n",
    "\n",
    "\n",
    "def apply_quantum_embedding(train_features, val_features, test_features, n_qubits=7):\n",
    "    q_layer = QuantumEmbeddingLayer(n_qubits=n_qubits, n_features=train_features.shape[1])\n",
    "    q_layer.eval()  # ÏûÑÎ≤†Îî© Ïö©ÎèÑ\n",
    "    with torch.no_grad():\n",
    "        train_q = q_layer(train_features)\n",
    "        val_q = q_layer(val_features)\n",
    "        test_q = q_layer(test_features)\n",
    "    print(f\"Quantum Embedding: {train_features.shape[1]} ‚Üí {n_qubits} qubits (output {train_q.shape[1]} dims)\")\n",
    "    return train_q, val_q, test_q\n",
    "\n",
    "\n",
    "# Train/Eval\n",
    "def train_cnn(model, train_loader, val_loader, config):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    for epoch in range(config.CNN_EPOCHS):\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(config.DEVICE), target.to(config.DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"[CNN] Epoch {epoch+1} finished\")\n",
    "        evaluate_model(model, val_loader, config.DEVICE, \"[CNN-VAL]\")\n",
    "    return model\n",
    "\n",
    "def train_mlp(model, train_feats, train_labels, val_feats, val_labels, test_feats, test_labels, config, name=\"MLP\",epochs=5):\n",
    "    train_dataset = TensorDataset(train_feats, train_labels)\n",
    "    val_dataset = TensorDataset(val_feats, val_labels)\n",
    "    test_dataset = TensorDataset(test_feats, test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(1, epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(config.DEVICE), target.to(config.DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # üîπ batch Í∞ÑÍ≤©Î≥Ñ loss Ï∂úÎ†•\n",
    "            if batch_idx % config.LOG_INTERVAL == 0:\n",
    "                print(f\"[{name}] Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}] \"\n",
    "                      f\"Loss: {loss.item():.6f}\")\n",
    "\n",
    "        # üîπ Í∞Å epochÎßàÎã§ validation/test Í≤∞Í≥º Ï∂úÎ†•\n",
    "        print(f\"[{name}] Epoch {epoch} finished\")\n",
    "        evaluate_model(model, val_loader, config.DEVICE, f\"[{name}-VAL]\")\n",
    "        evaluate_model(model, test_loader, config.DEVICE, f\"[{name}-TEST]\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, dataloader, device, prefix=\"\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = 100. * correct / len(dataloader.dataset)\n",
    "    print(f\"{prefix} Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "# Main\n",
    "def main():\n",
    "    config = Config()\n",
    "    torch.manual_seed(config.RANDOM_SEED)\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_mnist_loaders(config)\n",
    "    cnn = CNN(config.CNN_HIDDEN_DIM, config.NUM_CLASSES).to(config.DEVICE)\n",
    "    cnn = train_cnn(cnn, train_loader, val_loader, config)\n",
    "\n",
    "    # Feature extraction\n",
    "    train_feats, train_labels = extract_hidden_representations(cnn, train_loader, config.DEVICE, \"train\")\n",
    "    val_feats, val_labels = extract_hidden_representations(cnn, val_loader, config.DEVICE, \"val\")\n",
    "    test_feats, test_labels = extract_hidden_representations(cnn, test_loader, config.DEVICE, \"test\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PCA\")\n",
    "    print(\"=\"*50)\n",
    "    # PCA + MLP\n",
    "    train_pca, val_pca, test_pca = apply_pca(train_feats, val_feats, test_feats, config.PROJECTION_DIM)\n",
    "    pca_mlp = MLP(train_pca.shape[1], config.MLP_HIDDEN_DIM, config.NUM_CLASSES).to(config.DEVICE)\n",
    "    train_mlp(pca_mlp, train_pca, train_labels, val_pca, val_labels, test_pca, test_labels, config, \"PCA-MLP\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MLP\")\n",
    "    print(\"=\"*50)\n",
    "    # Random Projection + MLP\n",
    "    train_rp, val_rp, test_rp = apply_random_projection(train_feats, val_feats, test_feats, config.PROJECTION_DIM)\n",
    "    rp_mlp = MLP(train_rp.shape[1], config.MLP_HIDDEN_DIM, config.NUM_CLASSES).to(config.DEVICE)\n",
    "    train_mlp(rp_mlp, train_rp, train_labels, val_rp, val_labels, test_rp, test_labels, config, \"RP-MLP\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"QEB\")\n",
    "    print(\"=\"*50)\n",
    "    # Quantum Embedding + MLP\n",
    "    train_q, val_q, test_q = apply_quantum_embedding(train_feats, val_feats, test_feats, n_qubits=config.PROJECTION_DIM)\n",
    "    qeb_mlp = MLP(train_q.shape[1], config.MLP_HIDDEN_DIM, config.NUM_CLASSES).to(config.DEVICE)\n",
    "    train_mlp(qeb_mlp, train_q, train_labels, val_q, val_labels, test_q, test_labels, config, \"QEB-MLP\",epochs=30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8fb7e-844a-4e95-ab6a-de1bf5c1a126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f7356-6e37-46a4-bd82-92a347419d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist-cnn",
   "language": "python",
   "name": "mnist-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
